{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# _Multiple_ Linear Regression (MLR) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the population we have <ins>scalar</ins> random variables, $[Y,X_1,\\ldots,X_{k},e]$, that fulfill the following relationship\n",
    "\n",
    "$$\n",
    "Y=\\beta_0+\\beta_1 X_1+\\ldots+\\beta_k X_k+e\\text{,}\n",
    "$$\n",
    "\n",
    "where $E[e|X_1,\\ldots,X_{k}]=0$, there are no exact linear relationships among the set of regressors (covariates, confounders, independent variables, predictors, etc.) $[X_1,\\ldots,X_{k}]$, and var$(e|X_1,\\ldots,X_{k})<+\\infty$. The scalar random variable, $Y$, is called the outcome, or the dependent variable.\n",
    "\n",
    "\n",
    "\n",
    "<p style='text-align: right;'> <a href=\"https://en.wikipedia.org/wiki/Conditional_expectation\" style=\"color: #cc0000\">Conditional Expectation</a></p>\n",
    "\n",
    "<p style='text-align: right;'> <a href=\"https://en.wikipedia.org/wiki/Conditional_variance\" style=\"color: #cc0000\">Conditional Variance</a></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We observe a _random sample_ of $n$ observations taken from $[Y,X_1,\\ldots,X_{k},e]$, i.e., $\\{(y_i,x_{i,1},\\ldots,x_{i,k}):i=1,\\ldots,n\\}$. Therefore one has\n",
    "\n",
    "$$\n",
    "\\begin{array}\n",
    "[c]{c}\n",
    "y_{1}=\\beta_{0}+\\beta_{1}x_{1,1}+\\cdots+\\beta_{k}x_{1,k}+e_{1}\\\\\n",
    "y_{2}=\\beta_{0}+\\beta_{1}x_{2,1}+\\cdots+\\beta_{k}x_{2,k}+e_{2}\\\\\n",
    "y_{3}=\\beta_{0}+\\beta_{1}x_{3,1}+\\cdots+\\beta_{k}x_{3,k}+e_{3}\\\\\n",
    "\\vdots\\\\\n",
    "y_{n}=\\beta_{0}+\\beta_{1}x_{n,1}+\\cdots+\\beta_{k}x_{n,k}+e_{n}\n",
    "\\end{array}\n",
    "$$ or equivalently\n",
    "$$\\left[\n",
    "\\begin{array}\n",
    "[c]{c}\n",
    "y_{1}\\\\\n",
    "y_{2}\\\\\n",
    "y_{3}\\\\\n",
    "\\vdots\\\\\n",
    "y_{n}\n",
    "\\end{array}\n",
    "\\right]  =\\left[\n",
    "\\begin{array}\n",
    "[c]{cccc}\n",
    "1 & x_{1,1} & \\cdots & x_{1,k}\\\\\n",
    "1 & x_{2,1} & \\cdots & x_{2,k}\\\\\n",
    "1 & x_{3,1} & \\cdots & x_{3,k}\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "1 & x_{n,1} & \\cdots & x_{n,k}\n",
    "\\end{array}\n",
    "\\right]  \\left[\n",
    "\\begin{array}\n",
    "[c]{c}\n",
    "\\beta_{0}\\\\\n",
    "\\beta_{1}\\\\\n",
    "\\vdots\\\\\n",
    "\\beta_{k}\n",
    "\\end{array}\n",
    "\\right]  +\\left[\n",
    "\\begin{array}\n",
    "[c]{c}\n",
    "e_{1}\\\\\n",
    "e_{2}\\\\\n",
    "e_{3}\\\\\n",
    "\\vdots\\\\\n",
    "e_{n}\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "that can be rewritten in **matrix form**  as\n",
    "\n",
    "$$\n",
    "\\mathbf{y}=\\mathbf{X}\\mathbf{\\beta}+\\mathbf{e}\\text{,}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{y}$ is a $n\\times 1$ [vector](https://en.wikipedia.org/wiki/Vector_(mathematics_and_physics)), $\\mathbf{X}$ is a $n\\times(k+1)$ [matrix](https://en.wikipedia.org/wiki/Matrix_(mathematics)) - sometimes called the [*design matrix*](https://en.wikipedia.org/wiki/Design_matrix), $\\mathbf{\\beta}$ is a $(k+1)\\times 1$ vector of <ins>unknown</ins> parameters, and $\\mathbf{e}$ is a $n\\times 1$ vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "## removing everything from memory\n",
    "rm(list=ls())\n",
    "## turning all warnings off\n",
    "options(warn=-1)\n",
    "\n",
    "## installing the 'wooldridge' package if not previously installed\n",
    "if (!require(wooldridge)) install.packages('wooldridge')\n",
    "\n",
    "## loading the packages\n",
    "library(wooldridge)\n",
    "\n",
    "data(hprice2)\n",
    "\n",
    "##  hprice2\n",
    "##  Obs:   506\n",
    "\n",
    "##  1. price                    median housing price, $\n",
    "##  2. crime                    crimes committed per capita\n",
    "##  3. nox                      nitrous oxide, parts per 100 mill.\n",
    "##  4. rooms                    avg number of rooms per house\n",
    "##  5. dist                     weighted dist. to 5 employ centers\n",
    "##  6. radial                   accessibiliy index to radial hghwys\n",
    "##  7. proptax                  property tax per $1000\n",
    "##  8. stratio                  average student-teacher ratio\n",
    "##  9. lowstat                  % of people 'lower status'\n",
    "## 10. lprice                   log(price)\n",
    "## 11. lnox                     log(nox)\n",
    "## 12. lproptax                 log(proptax)\n",
    "\n",
    "head(hprice2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wooldridge as woo\n",
    "hprice2 = woo.dataWoo('hprice2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**<span style=\"color:blue\">Assumption MLR.1:</span>** $\\mathbf{y}=\\mathbf{X}\\mathbf{\\beta}+\\mathbf{e}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<ins>Example</ins>: We specify the following model \n",
    "\n",
    "$$\n",
    "\\texttt{lprice}=\\beta_{0}+\\beta_{1}\\texttt{lnox}+\\beta_{2}\\texttt{lproptax}+\\beta_{3}\\texttt{crime}+\\beta_{4}\\texttt{rooms}+\\beta_{5}\\texttt{dist}+\\beta_{6}\\texttt{radial}+\\beta_{7}\\texttt{stratio}+\\beta_{8}\\texttt{lowstat}+e\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "💻 We can use ```as.formula``` to specify the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## specifying the outcome variable (y) and regressors (X)\n",
    "outcome <- \"lprice\"\n",
    "predictors <- c(\"lnox\", \"lproptax\", \"crime\", \"rooms\", \"dist\", \"radial\", \"stratio\", \"lowstat\")\n",
    "\n",
    "## creating a specification of the linear model\n",
    "f <- as.formula(\n",
    "                paste(outcome, \n",
    "                      paste(predictors, collapse = \" + \"), \n",
    "                      sep = \" ~ \")\n",
    "                )\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lprice~lnox+lproptax+crime+rooms+dist+radial+stratio+lowstat\n"
     ]
    }
   ],
   "source": [
    "outcome = 'lprice'\n",
    "predictors = [\"lnox\", \"lproptax\", \"crime\", \"rooms\", \"dist\", \"radial\", \"stratio\", \"lowstat\"]\n",
    "f = outcome + \"~\" + \"+\".join(predictors)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**<span style=\"color:blue\">Assumption MLR.2:</span>** $\\{(y_i,x_{i,1},\\ldots,x_{i,k}):i=1,\\ldots,n\\}$ is a random sample (independent and identically distributed - i.i.d.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "💻 ```head``` allows us to visualize the structure of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# R\n",
    "head(subset(hprice2,select=c(outcome,predictors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lprice</th>\n",
       "      <th>lnox</th>\n",
       "      <th>lproptax</th>\n",
       "      <th>crime</th>\n",
       "      <th>rooms</th>\n",
       "      <th>dist</th>\n",
       "      <th>radial</th>\n",
       "      <th>stratio</th>\n",
       "      <th>lowstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.085809</td>\n",
       "      <td>1.682688</td>\n",
       "      <td>5.690360</td>\n",
       "      <td>0.006</td>\n",
       "      <td>6.57</td>\n",
       "      <td>4.09</td>\n",
       "      <td>1</td>\n",
       "      <td>15.300000</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.980402</td>\n",
       "      <td>1.545433</td>\n",
       "      <td>5.488938</td>\n",
       "      <td>0.027</td>\n",
       "      <td>6.42</td>\n",
       "      <td>4.97</td>\n",
       "      <td>2</td>\n",
       "      <td>17.799999</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.454495</td>\n",
       "      <td>1.545433</td>\n",
       "      <td>5.488938</td>\n",
       "      <td>0.027</td>\n",
       "      <td>7.18</td>\n",
       "      <td>4.97</td>\n",
       "      <td>2</td>\n",
       "      <td>17.799999</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.416311</td>\n",
       "      <td>1.521699</td>\n",
       "      <td>5.402678</td>\n",
       "      <td>0.032</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.06</td>\n",
       "      <td>3</td>\n",
       "      <td>18.700001</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.496787</td>\n",
       "      <td>1.521699</td>\n",
       "      <td>5.402678</td>\n",
       "      <td>0.069</td>\n",
       "      <td>7.15</td>\n",
       "      <td>6.06</td>\n",
       "      <td>3</td>\n",
       "      <td>18.700001</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lprice      lnox  lproptax  crime  rooms  dist  radial    stratio  \\\n",
       "0  10.085809  1.682688  5.690360  0.006   6.57  4.09       1  15.300000   \n",
       "1   9.980402  1.545433  5.488938  0.027   6.42  4.97       2  17.799999   \n",
       "2  10.454495  1.545433  5.488938  0.027   7.18  4.97       2  17.799999   \n",
       "3  10.416311  1.521699  5.402678  0.032   7.00  6.06       3  18.700001   \n",
       "4  10.496787  1.521699  5.402678  0.069   7.15  6.06       3  18.700001   \n",
       "\n",
       "   lowstat  \n",
       "0     4.98  \n",
       "1     9.14  \n",
       "2     4.03  \n",
       "3     2.94  \n",
       "4     5.33  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python\n",
    "hprice2[[outcome] + predictors].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**<span style=\"color:blue\">Assumption MLR.3:</span>** rank$[E(\\mathbf{x}_i\\mathbf{x}_i^\\prime)]=k+1$, where $\\mathbf{x}_i^\\prime=[1,x_{i,1},\\ldots,x_{i,k}]$. <p style='text-align: right;'> <a href=\"https://en.wikipedia.org/wiki/Rank_(linear_algebra)\" style=\"color: #cc0000\">Rank of a Matrix</a></p>\n",
    "<p style='text-align: right;'> <a href=\"https://en.wikipedia.org/wiki/Transpose\" style=\"color: #cc0000\">Transpose</a></p> <p style='text-align: right;'> <a href=\"https://en.wikipedia.org/wiki/Expected_value\" style=\"color: #cc0000\">Expected Value</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "💻 ```model.matrix``` creates a design matrix based on the declared predictors and includes a vector of ones by default as the first column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## asking R to print the design matrix for the chosen model\n",
    "X <- model.matrix(f,data=hprice2)\n",
    "dim(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 9)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## asking Python to print the design matrix for the chose model\n",
    "import patsy\n",
    "y, X = patsy.dmatrices(f,hprice2,return_type='matrix')\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## calculating & printing the sample counterpart of E[xx']\n",
    "X.X.n <- t(X)%*%X/nrow(X)\n",
    "X.X.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.           1.69309138   5.9314047    3.61153555   6.28405138\n",
      "    3.79575098   9.54940711  18.45928877  12.70148221]\n",
      " [  1.69309138   2.9070443   10.09557313   6.85653662  10.59639983\n",
      "    6.08414261  17.26048302  31.35248487  22.37223347]\n",
      " [  5.9314047   10.09557313  35.33835765  23.2951986   37.19007467\n",
      "   22.08598112  59.61578553 109.85126394  76.80060702]\n",
      " [  3.61153555   6.85653662  23.2951986   86.68969882  21.37703284\n",
      "    6.84866655  81.17709233  72.02683585  73.61199   ]\n",
      " [  6.28405138  10.59639983  37.19007467  21.37703284  39.9819642\n",
      "   24.15604997  58.72818179 115.46149344  76.72279698]\n",
      " [  3.79575098   6.08414261  22.08598112   6.84866655  24.15604997\n",
      "   18.83477015  27.18628454  69.02311519  40.67145505]\n",
      " [  9.54940711  17.26048302  59.61578553  81.17709233  58.72818179\n",
      "   27.18628454 166.85770751 185.0128508  151.23399206]\n",
      " [ 18.45928877  31.35248487 109.85126394  72.02683585 115.46149344\n",
      "   69.02311519 185.0128508  345.42684772 240.17717996]\n",
      " [ 12.70148221  22.37223347  76.80060702  73.61199     76.72279698\n",
      "   40.67145505 151.23399206 240.17717996 213.61370774]]\n"
     ]
    }
   ],
   "source": [
    "## calculating & printing the sample counterpart of E[xx']\n",
    "import numpy as np\n",
    "X_X_n = X.transpose()@X/X.shape[0]\n",
    "print(X_X_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## asking R to calculate the actual rank of the estimated E[xx']\n",
    "qr(X.X.n)$rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "## asking R to calculate the actual rank of the estimated E[xx']\n",
    "print(np.linalg.matrix_rank(X_X_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**<span style=\"color:blue\">Assumption MLR.4:</span>** $E[\\mathbf{e}|\\mathbf{X}]=\\mathbf{0}$.\n",
    "\n",
    "$$\n",
    "E[\\mathbf{e}|\\mathbf{X}]=\\left[\n",
    "\\begin{array}\n",
    "[c]{c}\n",
    "E[e_{1}|\\mathbf{X}]\\\\\n",
    "E[e_{2}|\\mathbf{X}]\\\\\n",
    "E[e_{3}|\\mathbf{X}]\\\\\n",
    "\\vdots\\\\\n",
    "E[e_{n}|\\mathbf{X}]\n",
    "\\end{array}\n",
    "\\right]  =\\left[\n",
    "\\begin{array}\n",
    "[c]{c}\n",
    "0\\\\\n",
    "0\\\\\n",
    "0\\\\\n",
    "\\vdots\\\\\n",
    "0\n",
    "\\end{array}\n",
    "\\right]=\\mathbf{0}.  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**<span style=\"color:blue\">Assumption MLR.5:</span>** var$(\\mathbf{e}|\\mathbf{X})=E[\\mathbf{e}\\mathbf{e}^{\\prime}|\\mathbf{X}]=\\mathbf{D}$, i.e.,\n",
    "\n",
    "$$\n",
    "E[\\mathbf{e}\\mathbf{e}^{\\prime}|\\mathbf{X}]=\n",
    "\\begin{bmatrix}\n",
    "E[e_{1}^{2}|\\mathbf{X}] & 0 & \\cdots & 0\\\\\n",
    "0 & E[e_{2}^{2}|\\mathbf{X}] & \\cdots & 0\\\\\n",
    "0 & 0 & \\cdots & 0\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "0 & 0 & \\cdots & E[e_{n}^{2}|\\mathbf{X}]\n",
    "\\end{bmatrix}  = \\mathbf{D}\n",
    "$$\n",
    "\n",
    "where $\\vert\\mathbf{D}\\vert < +\\infty$.\n",
    "\n",
    "<p style='text-align: right;'> <a href=\"https://en.wikipedia.org/wiki/Determinant\" style=\"color: #cc0000\">Determinant</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The *Ordinary Least Squares* (OLS) Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Define the Sum of Squared Errors ($\\mathrm{SSE}$) as a function of any candidate guess, $\\mathbf{b}=[b_{0},b_{1},\\cdots,b_{k}]^{\\prime}$, for the unknown $[\\beta_{0},\\beta_{1},\\beta_{2},\\cdots,\\beta_{k}]^{\\prime}\\equiv\\mathbf{\\beta}$, i.e.,\n",
    "\n",
    "$$\n",
    "\\mathrm{SSE}(\\mathbf{b})=\\Sigma_{i=1}^{n}(y_{i}-b_{0}-b_{1}x_{1,i}-b_{2}x_{2,i}\n",
    "-\\cdots-b_{k}x_{k,i})^{2}=(\\mathbf{y}-\\mathbf{Xb})^{\\prime}(\\mathbf{y}\n",
    "-\\mathbf{Xb})\n",
    "$$\n",
    "\n",
    "By standard [matrix calculus](https://en.wikipedia.org/wiki/Matrix_calculus) one has\n",
    "$$\n",
    "\\frac{\\partial \\mathrm{SSE}(\\mathbf{b})}{\\partial\\mathbf{b}}=\\left[\n",
    "\\begin{array}\n",
    "[c]{c}\n",
    "\\partial \\mathrm{SSE}(\\mathbf{b})/\\partial b_{0}\\\\\n",
    "\\partial \\mathrm{SSE}(\\mathbf{b})/\\partial b_{1}\\\\\n",
    "\\partial \\mathrm{SSE}(\\mathbf{b})/\\partial b_{2}\\\\\n",
    "\\vdots\\\\\n",
    "\\partial \\mathrm{SSE}(\\mathbf{b})/\\partial b_{k}\n",
    "\\end{array}\n",
    "\\right]  =-2\\mathbf{X}^{\\prime}(\\mathbf{y}-\\mathbf{Xb})\\text{,}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "and\n",
    "\n",
    "$$\n",
    "\\frac{\\partial^{2}\\mathrm{SSE}(\\mathbf{b})}{\\partial\\mathbf{b}\\partial\\mathbf{b}\n",
    "^{\\prime}}=\\left[\n",
    "\\begin{array}\n",
    "[c]{cccc}\n",
    "\\partial^{2}\\mathrm{SSE}(\\mathbf{b})/\\partial b_{0}^{2} & \\partial^{2}\\mathrm{SSE}(\\mathbf{b}\n",
    ")/\\partial b_{0}\\partial b_{1} & \\cdots & \\partial^{2}\\mathrm{SSE}(\\mathbf{b})/\\partial\n",
    "b_{0}\\partial b_{k}\\\\\n",
    "\\partial^{2}\\mathrm{SSE}(\\mathbf{b})/\\partial b_{1}\\partial b_{0} & \\partial\n",
    "^{2}\\mathrm{SSE}(\\mathbf{b})/\\partial b_{1}^{2} & \\cdots & \\partial^{2}\\mathrm{SSE}(\\mathbf{b}\n",
    ")/\\partial b_{1}\\partial b_{k}\\\\\n",
    "\\partial^{2}\\mathrm{SSE}(\\mathbf{b})/\\partial b_{2}\\partial b_{0} & \\partial\n",
    "^{2}\\mathrm{SSE}(\\mathbf{b})/\\partial b_{2}\\partial b_{1} & \\cdots & \\partial\n",
    "^{2}\\mathrm{SSE}(\\mathbf{b})/\\partial b_{2}\\partial b_{k}\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "\\partial^{2}\\mathrm{SSE}(\\mathbf{b})/\\partial b_{k}\\partial b_{0} & \\partial\n",
    "^{2}\\mathrm{SSE}(\\mathbf{b})/\\partial b_{k}\\partial b_{1} & \\cdots & \\partial\n",
    "^{2}\\mathrm{SSE}(\\mathbf{b})/\\partial b_{k}^{2}\n",
    "\\end{array}\n",
    "\\right]  =2\\mathbf{X}^{\\prime}\\mathbf{X}\\text{,}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{X}^{\\prime}\\mathbf{X}$ is a [positive definite matrix](https://en.wikipedia.org/wiki/Definiteness_of_a_matrix) by **<span style=\"color:blue\">Assumption MLR.3</span>**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## printing 2X'X\n",
    "2*t(X)%*%X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1012.           1713.40847802   6002.58155155   3654.87397676\n",
      "    6359.45999765   3841.2999959    9664.          18680.80023766\n",
      "   12853.89999175]\n",
      " [  1713.40847802   2941.92883376  10216.72001235   6938.8150594\n",
      "   10723.55663263   6157.15232569  17467.60881209  31728.71468777\n",
      "   22640.70027378]\n",
      " [  6002.58155155  10216.72001235  35762.41793831  23574.74098372\n",
      "   37636.35556945  22351.0128984   60331.17495346 111169.47910286\n",
      "   77722.21430324]\n",
      " [  3654.87397676   6938.8150594   23574.74098372  87729.97520854\n",
      "   21633.55723406   6930.85055137  82151.21743452  72891.15787958\n",
      "   74495.33387686]\n",
      " [  6359.45999765  10723.55663263  37636.35556945  21633.55723406\n",
      "   40461.74776667  24445.92256768  59432.91997051 116847.03135794\n",
      "   77643.47053913]\n",
      " [  3841.2999959    6157.15232569  22351.0128984    6930.85055137\n",
      "   24445.92256768  19060.78738724  27512.51995349  69851.3925711\n",
      "   41159.51251029]\n",
      " [  9664.          17467.60881209  60331.17495346  82151.21743452\n",
      "   59432.91997051  27512.51995349 168860.         187233.0050106\n",
      "  153048.79996276]\n",
      " [ 18680.80023766  31728.71468777 111169.47910286  72891.15787958\n",
      "  116847.03135794  69851.3925711  187233.0050106  349571.96989769\n",
      "  243059.30612074]\n",
      " [ 12853.89999175  22640.70027378  77722.21430324  74495.33387686\n",
      "   77643.47053913  41159.51251029 153048.79996276 243059.30612074\n",
      "  216177.07223356]]\n"
     ]
    }
   ],
   "source": [
    "## printing 2X'X\n",
    "print(2*X.transpose()@X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Therefore $\\left.  \\partial \\mathrm{SSE}(\\mathbf{b})/\\partial\\mathbf{b}\\right\\vert _{\\mathbf{b}=\\widehat{\\boldsymbol{\\beta}}\n",
    "}=\\mathbf{0}$ defines a minima, i.e.,\n",
    "\n",
    "$$\\widehat{\\boldsymbol{\\beta}}=(\\mathbf{X}\n",
    "^{\\prime}\\mathbf{X})^{-1}\\mathbf{X}^{\\prime}\\mathbf{y}.$$\n",
    "\n",
    "Here we have used the\n",
    "notation $\\mathbf{A}^{-1}$ to denote the inverse of a matrix $\\mathbf{A}$.\n",
    "\n",
    "<p style='text-align: right;'> <a href=\"https://en.wikipedia.org/wiki/Euclidean_distance\" style=\"color: #cc0000\">Euclidean Distance</a></p>\n",
    "<p style='text-align: right;'> <a href=\"https://en.wikipedia.org/wiki/Invertible_matrix\" style=\"color: #cc0000\">Inverse</a></p>\n",
    "<p style='text-align: right;'> <a href=\"https://en.wikipedia.org/wiki/Maxima_and_minima\" style=\"color: #cc0000\">Maxima</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "💻 Calculating the OLS estimator by hand first and then using the highly optimized ```lm``` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## calculating OLS by hand\n",
    "solve(t(X)%*%X)%*%(t(X)%*%hprice2$lprice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.651615]\n",
      " [-0.450333]\n",
      " [-0.227375]\n",
      " [-0.011265]\n",
      " [ 0.098998]\n",
      " [-0.048805]\n",
      " [ 0.011469]\n",
      " [-0.040418]\n",
      " [-0.028268]]\n"
     ]
    }
   ],
   "source": [
    "## calculating OLS by hand\n",
    "from numpy.linalg import inv\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "print(inv(X.transpose()@X)@X.transpose()@y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## calculating OLS using the `lm' command in R\n",
    "coef(lm(f,data=hprice2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept    12.651615\n",
      "lnox         -0.450333\n",
      "lproptax     -0.227375\n",
      "crime        -0.011265\n",
      "rooms         0.098998\n",
      "dist         -0.048805\n",
      "radial        0.011469\n",
      "stratio      -0.040418\n",
      "lowstat      -0.028268\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## calculating OLS using the `formula' framework in statsmodels in Python\n",
    "import statsmodels.formula.api as smf\n",
    "ols = smf.ols(formula=f,data=hprice2).fit()\n",
    "print(ols.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The _Algebra_ of the OLS Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "💻 We now save the ```lm``` object and call it ```ols```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ols <- lm(f,data=hprice2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols = smf.ols(formula=f,data=hprice2).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*Fitted Values*: $\\widehat{\\mathbf{y}}=\\mathbf{X}\\widehat{\\boldsymbol{\\beta}}$.\n",
    "\n",
    "*Residuals*: $\\widehat{\\mathbf{e}}=\\mathbf{y}-\\mathbf{X} \\widehat{\\boldsymbol{\\beta}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## OLS: printing the first 6 outcomes, fitted values, & residuals\n",
    "head(data.frame(y=hprice2$lprice,y.hat=fitted(ols),e.hat=resid(ols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>y_hat</th>\n",
       "      <th>e_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.085809</td>\n",
       "      <td>10.303026</td>\n",
       "      <td>-0.217217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.980402</td>\n",
       "      <td>10.145427</td>\n",
       "      <td>-0.165025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.454495</td>\n",
       "      <td>10.365117</td>\n",
       "      <td>0.089378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.416311</td>\n",
       "      <td>10.330250</td>\n",
       "      <td>0.086061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.496787</td>\n",
       "      <td>10.277121</td>\n",
       "      <td>0.219666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.264688</td>\n",
       "      <td>10.209674</td>\n",
       "      <td>0.055013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           y      y_hat     e_hat\n",
       "0  10.085809  10.303026 -0.217217\n",
       "1   9.980402  10.145427 -0.165025\n",
       "2  10.454495  10.365117  0.089378\n",
       "3  10.416311  10.330250  0.086061\n",
       "4  10.496787  10.277121  0.219666\n",
       "5  10.264688  10.209674  0.055013"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## OLS: printing the first 6 outcomes, fitted values, & residuals\n",
    "import pandas as pd\n",
    "pd.DataFrame({'y':hprice2['lprice'],'y_hat':ols.fittedvalues.values,'e_hat':ols.resid}).head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*Orthogonality*: $\\mathbf{X}^{\\prime}\\widehat{\\mathbf{e}}=\\mathbf{0}$.\n",
    "\n",
    "✏️ This follows from $\\left.  \\partial \\mathrm{SSE}(\\mathbf{b})/\\partial\\mathbf{b}\\right\\vert _{\\mathbf{b}=\\widehat{\\boldsymbol{\\beta}}\n",
    "}=\\mathbf{0}$, since $$-2\\mathbf{X}^{\\prime}(\\mathbf{y}-\\mathbf{X\\widehat{\\boldsymbol{\\beta}}})=-2\\mathbf{X}^{\\prime}\\widehat{\\mathbf{e}}=\\mathbf{0}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## OLS: showing the orthogonality of the residuals and predictors\n",
    "round(t(X)%*%resid(ols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## OLS: showing the orthogonality of the residuals and predictors\n",
    "np.round(X.transpose()@ols.resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*Analysis-of-variance*:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\sum_{i=1}^{n}\\left(y_{i}-\\bar{y}\\right)^{2}&=\\sum_{i=1}^{n}\\left(\\widehat{y}_{i}-\\bar{y}\\right)^{2}+\\sum_{i=1}^{n} \\widehat{e}_{i}^{2},\\\\\n",
    "\\text{Total Sum of Squares}&=\\text{Explained Sum of Squares} + \\text{Residual Sum of Squares},\\\\\n",
    "\\left(\\mathbf{y}-\\boldsymbol{\\iota}_{n} \\bar{y}\\right)^{\\prime}\\left(\\mathbf{y}-\\boldsymbol{\\iota}_{n} \\bar{y}\\right)&=\\left(\\widehat{\\mathbf{y}}-\\boldsymbol{\\iota}_{n} \\bar{y}\\right)^{\\prime}\\left(\\widehat{\\mathbf{y}}-\\boldsymbol{\\iota}_{n} \\bar{y}\\right)+\\widehat{\\mathbf{e}}^{\\prime} \\widehat{\\mathbf{e}}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $\\boldsymbol{\\iota}_n$ is a $n\\times 1$ vector of ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "anova(ols)\n",
    "\n",
    "## OLS: total sum of squares\n",
    "sum(anova(ols)[,2])\n",
    "\n",
    "## OLS: explained sum of squares\n",
    "sum(anova(ols)[-9,2])\n",
    "\n",
    "## OLS: residual sum of squares\n",
    "sum(anova(ols)[9,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.58222496430884\n",
      "64.8931494608045\n",
      "19.689075503504338\n"
     ]
    }
   ],
   "source": [
    "## OLS: total sum of squares\n",
    "print(ols.centered_tss)\n",
    "\n",
    "## OLS: explained sum of squares\n",
    "print(ols.ess)\n",
    "\n",
    "## OLS: residual sum of squares\n",
    "print(ols.ssr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*Coefficient of Determination* (*$R^2$*):\n",
    "\n",
    "$$\n",
    "R^{2}=\\frac{\\sum_{i=1}^{n}\\left(\\widehat{y}_{i}-\\bar{y}\\right)^{2}}{\\sum_{i=1}^{n}\\left(y_{i}-\\bar{y}\\right)^{2}}=1-\\frac{\\sum_{i=1}^{n} \\widehat{e}_{i}^{2}}{\\sum_{i=1}^{n}\\left(y_{i}-\\bar{y}\\right)^{2}}.\n",
    "$$\n",
    "\n",
    "✏️ More generally the $R^2$ in most models (linear and *non-linear*) is defined as $(\\widehat{\\text{corr}(\\widehat{y},y)})^2$, i.e., the squared of the sample correlation coefficient between the true values and the fitted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## OLS: R2 (manually)\n",
    "sum(anova(ols)[-9,2])/sum(anova(ols)[,2])\n",
    "\n",
    "## OLS: R2 (from lm)\n",
    "summary(ols)$r.squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7672197023451139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.767219702345114"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## OLS: R2 (manually)\n",
    "print(ols.ess/ols.centered_tss)\n",
    "\n",
    "## OLS: R2 (from lm)\n",
    "ols.rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*Adjusted R-squared* ($\\overline{R}^2$):\n",
    "\n",
    "$$\n",
    "\\overline{R}^{2}=1-\\frac{(n-1) \\sum_{i=1}^{n} \\widehat{e}_{i}^{2}}{(n-k-1) \\sum_{i=1}^{n}\\left(y_{i}-\\bar{y}\\right)^{2}}\n",
    "$$\n",
    "\n",
    "✏️ Unlike the $R^2$ which cannot decrease as $k$ increases, $\\overline{R}^2$ can either increase _or_ decrease with $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## OLS: adj. R2 (manually)\n",
    "1-(sum(anova(ols)[9,2])/sum(anova(ols)[,2]))*(sum(anova(ols)[,1])/anova(ols)[9,1])\n",
    "\n",
    "## OLS: adj. R2 (from lm)\n",
    "summary(ols)$adj.r.squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7634727357832647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7634727357832647"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## OLS: adj. R2 (manually)\n",
    "print(1-((ols.nobs-1)/ols.df_resid)*(ols.ssr/ols.centered_tss))\n",
    "\n",
    "## OLS: adj. R2 (from lm)\n",
    "ols.rsquared_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*Leverage Values*:\n",
    "\n",
    "The [leverage values](https://en.wikipedia.org/wiki/Leverage_(statistics)) for the design matrix $\\mathbf{X}$ are the [diagonal](https://en.wikipedia.org/wiki/Main_diagonal) elements of the matrix $\\mathbf{X}\\left(\\mathbf{X}^{\\prime} \\mathbf{X}\\right)^{-1} \\mathbf{X}^{\\prime}$. There are $n$ leverage values, and are typically written as $h_{i i}$ for $i=1, \\ldots, n$. since\n",
    "\n",
    "$$\n",
    "\\mathbf{X}\\left(\\mathbf{X}^{\\prime} \\mathbf{X}\\right)^{-1} \\mathbf{X}^{\\prime}=\n",
    "\\left(\\begin{array}{c}{\\mathbf{x}_{1}^{\\prime}} \\\\ {\\mathbf{x}_{2}^{\\prime}} \\\\ {\\vdots} \\\\ {\\mathbf{x}_{n}^{\\prime}}\\end{array}\\right)\\left(\\mathbf{X}^{\\prime} \\mathbf{X}\\right)^{-1}\\left(\\begin{array}{llll}{\\mathbf{x}_{1}} & {\\mathbf{x}_{2}} & {\\cdots} & {\\mathbf{x}_{n}}\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "they are\n",
    "$$\n",
    "h_{i i}=\\mathbf{x}_{i}^{\\prime}\\left(\\mathbf{X}^{\\prime} \\mathbf{X}\\right)^{-1} \\mathbf{x}_{i}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## OLS: leverage values\n",
    "hii <- hatvalues(ols)\n",
    "head(hii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.009728, 0.004655, 0.007459, 0.011596, 0.011471])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## OLS: leverage values\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "\n",
    "hii = OLSInfluence(ols).hat_matrix_diag\n",
    "hii[0:5,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*Prediction Error* (leave-one-out residual or prediction residual):\n",
    "\n",
    "$$\\widetilde{e}_{i}=y_{i}-\\widetilde{y}_{i},$$ \n",
    "\n",
    "where we use the leave-one-out predicted value for $y_i$, i.e.,\n",
    "\n",
    "$$\n",
    "\\widetilde{y}_{i}=\\mathbf{x}_{i}^{\\prime} \\widehat{\\boldsymbol{\\beta}}_{(-i)},$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\begin{aligned} \\widehat{\\boldsymbol{\\beta}}_{(-i)} &=\\left(\\sum_{j \\neq i} \\mathbf{x}_{j} \\mathbf{x}_{j}^{\\prime}\\right)^{-1}\\left(\\sum_{j \\neq i} \\mathbf{x}_{j} y_{j}\\right) \\\\ &=\\left(\\mathbf{X}^{\\prime} \\mathbf{X}-\\mathbf{x}_{i} \\mathbf{x}_{i}^{\\prime}\\right)^{-1}\\left(\\mathbf{X}^{\\prime} \\mathbf{y}-\\mathbf{x}_{i} y_{i}\\right) \\\\ &=\\left(\\mathbf{X}_{(-i)}^{\\prime} \\mathbf{X}_{(-i)}\\right)^{-1} \\mathbf{X}_{(-i)}^{\\prime} \\mathbf{y}_{(-i)}. \\end{aligned}\n",
    "$$\n",
    "\n",
    "Here, $\\mathbf{X}_{(-i)}$ and $\\mathbf{y}_{(-i)}$ are the data matrices omitting the $i$th row. The notation $\\widehat{\\boldsymbol{\\beta}}_{(-i)}$ or $\\widehat{\\boldsymbol{\\beta}}_{-i}$ is commonly\n",
    "used to denote an estimator with the $i$th observation omitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "✏️ There is a leave-one-out estimator for each observation, $i=1,\\ldots,n$ so we have $n$ such estimators, and one can show that\n",
    "\n",
    "$$\n",
    "\\widehat{\\boldsymbol{\\beta}}_{(-i)}=\\widehat{\\boldsymbol{\\beta}}-\\left(\\mathbf{X}^{\\prime} \\mathbf{X}\\right)^{-1} \\mathbf{x}_{i} \\widetilde{e}_{i},\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\widetilde{e}_{i}=\\left(1-h_{i i}\\right)^{-1} \\widehat{e}_{i}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## OLS: original residuals\n",
    "e.hat <- resid(ols)\n",
    "\n",
    "## OLS: calculating the prediction error\n",
    "e.tilde <- resid(ols)/(1-hii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OLS: original residuals\n",
    "e_hat = ols.resid\n",
    "\n",
    "## OLS: calculating the prediction error\n",
    "e_tilde = ols.resid/(1-hii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## OLS: manually re-calculating OLS without observation 156\n",
    "data.frame(beta.hat=coef(ols),\n",
    "           beta.hat.i=coef(ols)-solve(t(X)%*%X)%*%X[156,]%*%e.tilde[156])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beta_hat</th>\n",
       "      <th>beta_hat_i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>12.651615</td>\n",
       "      <td>12.633795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lnox</th>\n",
       "      <td>-0.450333</td>\n",
       "      <td>-0.438075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lproptax</th>\n",
       "      <td>-0.227375</td>\n",
       "      <td>-0.227047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crime</th>\n",
       "      <td>-0.011265</td>\n",
       "      <td>-0.011239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rooms</th>\n",
       "      <td>0.098998</td>\n",
       "      <td>0.098922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dist</th>\n",
       "      <td>-0.048805</td>\n",
       "      <td>-0.048356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radial</th>\n",
       "      <td>0.011469</td>\n",
       "      <td>0.011339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stratio</th>\n",
       "      <td>-0.040418</td>\n",
       "      <td>-0.040631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lowstat</th>\n",
       "      <td>-0.028268</td>\n",
       "      <td>-0.028320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            beta_hat  beta_hat_i\n",
       "Intercept  12.651615   12.633795\n",
       "lnox       -0.450333   -0.438075\n",
       "lproptax   -0.227375   -0.227047\n",
       "crime      -0.011265   -0.011239\n",
       "rooms       0.098998    0.098922\n",
       "dist       -0.048805   -0.048356\n",
       "radial      0.011469    0.011339\n",
       "stratio    -0.040418   -0.040631\n",
       "lowstat    -0.028268   -0.028320"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## OLS: manually re-calculating OLS without observation 156\n",
    "pd.DataFrame({'beta_hat':ols.params,\n",
    "           'beta_hat_i':ols.params-inv(X.transpose()@X)@(X[155,]*e_tilde[155])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*Estimation of Error Variance*:\n",
    "\n",
    "The _unconditional_ error variance $\\sigma^2=E(e^2_{i})$ can be estimated as\n",
    "\n",
    "1. Estimator 1:\n",
    "\n",
    "$$s^{2}=\\frac{1}{n-k-1} \\sum_{i=1}^{n} \\widehat{e}_{i}^{2}.$$\n",
    "\n",
    "2. Estimator 2:\n",
    "\n",
    "$$\\widehat{\\sigma}^{2}=\\frac{1}{n} \\sum_{i=1}^{n} \\widehat{e}_{i}^{2}.$$\n",
    "\n",
    "3. Estimator 3:\n",
    "\n",
    "$$\\bar{\\sigma}^{2}=\\frac{1}{n} \\sum_{i=1}^{n} \\tilde{e}_{i}^{2}=\\frac{1}{n} \\sum_{i=1}^{n}\\left(1-h_{i i}\\right)^{-2} \\widehat{e}_{i}^{2}.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "✏️ When $k / n$ is small (typically, this occurs when $n$ is large), the estimators $\\widehat{\\sigma}^{2}, s^{2}$ and $\\overline{\\sigma}^{2}$ are likely to be similar to one another. However, if $k / n$ is large then $s^{2}$ and $\\overline{\\sigma}^{2}$ are generally preferred to $\\widehat{\\sigma}^{2}$. Consequently it is best to use one of the bias-corrected variance estimators in applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## OLS: error variance estimators\n",
    "s2 <- sum(e.hat^2)/(length(e.hat)-dim(X)[2])\n",
    "sigma.hat2 <- sum(e.hat^2)/length(e.hat)\n",
    "sigma.bar2 <- sum((e.hat/(1-hii))^2)/length(e.hat)\n",
    "data.frame(s2=s2,sigma.hat2=sigma.hat2,sigma.bar2=sigma.bar2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         s2  sigma_hat2  sigma_bar2\n",
      "0  0.039616    0.038911    0.041166\n"
     ]
    }
   ],
   "source": [
    "## OLS: error variance estimators\n",
    "s2 = ols.ssr/ols.df_resid\n",
    "sigma_hat2 = ols.ssr/ols.nobs\n",
    "sigma_bar2 = ((e_hat/(1-hii))**2).sum(axis=0)/ols.nobs\n",
    "\n",
    "## Because all values are 'scalars' we need to pass them inside []\n",
    "print(pd.DataFrame({'s2':[s2],'sigma_hat2':[sigma_hat2],'sigma_bar2':[sigma_bar2]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The _Finite Sample_ Properties of the OLS Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**<span style=\"color:blue\">Mean of OLS:</span>** Under Assumptions MLR.1, MLR.2, MLR.3, and MLR.4 one has\n",
    "\n",
    "$\\begin{aligned} E(\\widehat{\\boldsymbol{\\beta}} | \\mathbf{X}) &=E\\left(\\left(\\mathbf{X}^{\\prime} \\mathbf{X}\\right)^{-1} \\mathbf{X}^{\\prime} \\mathbf{y} | \\mathbf{X}\\right) \\\\ &=\\left(\\mathbf{X}^{\\prime} \\mathbf{X}\\right)^{-1} \\mathbf{X}^{\\prime} E(\\mathbf{y} | \\mathbf{X}) \\\\ &=\\left(\\mathbf{X}^{\\prime} \\mathbf{X}\\right)^{-1} \\mathbf{X}^{\\prime} \\mathbf{X} \\boldsymbol{\\beta} \\\\ &=\\boldsymbol{\\beta} \\end{aligned}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**<span style=\"color:blue\">Variance of OLS:</span>** Firstly, let us use the notation $\\mathbf{V}_{\\widehat{\\beta}} \\stackrel{d e f}{=} \\text{var}(\\widehat{\\boldsymbol{\\beta}} | \\mathbf{X})$ and recall from Assumption MLR.5 that var$(\\mathbf{e}|\\mathbf{X})=E[\\mathbf{e}\\mathbf{e}^{\\prime}|\\mathbf{X}]=\\mathbf{D}$. Then under Assumptions MLR.1, MLR.2, MLR.3, MLR.4, and MLR.5 one has\n",
    "\n",
    "$\\begin{aligned} \\mathbf{V}_{\\widehat{\\beta}} &=\\text{var}(\\widehat{\\boldsymbol{\\beta}} | \\mathbf{X}) \\\\ &=\\left(\\mathbf{X}^{\\prime} \\mathbf{X}\\right)^{-1}\\left(\\mathbf{X}^{\\prime} \\mathbf{D} \\mathbf{X}\\right)\\left(\\mathbf{X}^{\\prime} \\mathbf{X}\\right)^{-1} \\end{aligned}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "✏️ If one has *homoskedasticity*, i.e., $\\mathbf{D}=\\sigma^2\\mathbf{I}_n$, then $\\mathbf{V}_{\\widehat{\\boldsymbol{\\beta}}}=\\sigma^{2}\\left(\\mathbf{X}^{\\prime} \\mathbf{X}\\right)^{-1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Asymptotic Properties of the OLS Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**<span style=\"color:blue\">(Asymptotic) Consistency of OLS:</span>** As $n\\rightarrow\\infty$, under Assumptions MLR.1, MLR.2, MLR.3 and MLR.4 one has\n",
    "\n",
    "$$\n",
    "\\widehat{\\boldsymbol{\\beta}}\\stackrel{p}{\\longrightarrow} \\boldsymbol{\\beta}\n",
    "$$\n",
    "\n",
    "<p style='text-align: right;'> <a href=\"https://en.wikipedia.org/wiki/Convergence_of_random_variables#Convergence_in_probability\" style=\"color: #cc0000\">Convergence in probability</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**<span style=\"color:blue\">(Asymptotic) Distribution of OLS:</span>** As $n\\rightarrow\\infty$, under Assumptions MLR.1, MLR.2, MLR.3, MLR.4, and MLR.5 one has\n",
    "\n",
    "$$\\sqrt{n}(\\widehat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta}) \\stackrel{d}{\\longrightarrow} \\mathbf{N}\\left(\\mathbf{0}, \\mathbf{V}_{\\boldsymbol{\\beta}}\\right),$$\n",
    "\n",
    "<p style='text-align: right;'> <a href=\"https://en.wikipedia.org/wiki/Convergence_of_random_variables#Convergence_in_distribution\" style=\"color: #cc0000\">Convergence in Distribution</a></p>\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\mathbf{V}_{\\boldsymbol{\\beta}}=E(\\mathbf{x}_i\\mathbf{x}_i^{\\prime})^{-1}E[\\mathbf{x}_{i}E(e_i^2|\\mathbf{x}_i)\\mathbf{x}_{i}^{\\prime}]E(\\mathbf{x}_i\\mathbf{x}_i^{\\prime})^{-1},\n",
    "$$\n",
    "\n",
    "and the notation $\\mathbf{N}(\\boldsymbol{\\mu},\\boldsymbol{\\Sigma})$ denotes a [multivariate normal distribution](https://en.wikipedia.org/wiki/Multivariate_normal_distribution). $\\mathbf{V}_{\\boldsymbol{\\beta}}$ is the asymptotic (asy.) [variance-covariance matrix](https://en.wikipedia.org/wiki/Covariance_matrix) of $\\sqrt{n}(\\widehat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta})$ and therefore $n^{-1}\\mathbf{V}_{\\boldsymbol{\\beta}}$ is the asymptotic variance of $\\widehat{\\boldsymbol{\\beta}}$ and it is generally _unknown_ and needs to be estimated.\n",
    "\n",
    "$$\n",
    "n^{-1}\\mathbf{V}_{\\boldsymbol{\\beta}}=\\left[\n",
    "\\begin{array}\n",
    "[c]{cccc}\n",
    "\\text{asy. var}(\\widehat{\\beta}_{0}) & \\text{asy. cov}(\\widehat{\\beta}\n",
    "_{0},\\widehat{\\beta}_{1}) & \\cdots & \\text{asy. cov}(\\widehat{\\beta}\n",
    "_{0},\\widehat{\\beta}_{k})\\\\\n",
    "\\text{asy. cov}(\\widehat{\\beta}_{1},\\widehat{\\beta}_{0}) & \\text{asy.\n",
    "var}(\\widehat{\\beta}_{1}) & \\cdots & \\text{asy. cov}(\\widehat{\\beta}\n",
    "_{1},\\widehat{\\beta}_{k})\\\\\n",
    "\\text{asy. cov}(\\widehat{\\beta}_{2},\\widehat{\\beta}_{0}) & \\text{asy.\n",
    "cov}(\\widehat{\\beta}_{2},\\widehat{\\beta}_{1}) & \\cdots & \\text{asy.\n",
    "cov}(\\widehat{\\beta}_{2},\\widehat{\\beta}_{k})\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "\\text{asy. cov}(\\widehat{\\beta}_{k},\\widehat{\\beta}_{0}) & \\text{asy.\n",
    "cov}(\\widehat{\\beta}_{k},\\widehat{\\beta}_{1}) & \\cdots & \\text{asy.\n",
    "var}(\\widehat{\\beta}_{k})\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "✏️ Notice that $\\mathbf{V}_{\\boldsymbol{\\beta}}$ is a $(k+1)\\times(k+1)$ [square](https://en.wikipedia.org/wiki/Square_matrix), [symmetric](https://en.wikipedia.org/wiki/Symmetric_matrix), and [positive semi-definite](https://en.wikipedia.org/wiki/Definiteness_of_a_matrix) matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<ins>(Asymptotic) OLS Variance Estimation</ins>:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Firstly notice that\n",
    "\n",
    "$$\n",
    "\\begin{aligned} n\\mathbf{V}_{\\widehat{\\boldsymbol{\\beta}}} &=n\\text{ var}(\\widehat{\\boldsymbol{\\beta}} | \\mathbf{X}) \\\\ &=\\left(n^{-1}\\mathbf{X}^{\\prime} \\mathbf{X}\\right)^{-1}\\left(n^{-1}\\mathbf{X}^{\\prime} \\mathbf{D} \\mathbf{X}\\right)\\left(n^{-1}\\mathbf{X}^{\\prime} \\mathbf{X}\\right)^{-1}, \\end{aligned}\n",
    "$$\n",
    "\n",
    "and it has been shown that\n",
    "\n",
    "$$n \\mathbf{V}_{\\widehat{\\boldsymbol{\\beta}}} \\stackrel{p}{\\longrightarrow} \\mathbf{V}_{\\boldsymbol{\\beta}}$$\n",
    "\n",
    "<p style='text-align: right;'> <a href=\"https://en.wikipedia.org/wiki/Convergence_of_random_variables#Convergence_in_probability\" style=\"color: #cc0000\">Convergence in probability</a></p>\n",
    "\n",
    "🛑 Unfortunately $n\\mathbf{V}_{\\widehat{\\boldsymbol{\\beta}}}$ is _infeasible_ as matrix $\\mathbf{D}$ (defined in Assumption MLR.5) is *not known*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**<span style=\"color:red\">HC0:</span>**\n",
    "\n",
    "$$\n",
    "\\widehat{\\mathbf{V}}_{\\widehat{\\boldsymbol{\\beta}}}^{\\mathrm{HC0}}=\\left(\\mathbf{X}^{\\prime} \\mathbf{X}\\right)^{-1}\\left(\\sum_{i=1}^{n} \\mathbf{x}_{i} \\widehat{e}_{i}^{2}\\mathbf{x}_{i}^{\\prime} \\right)\\left(\\mathbf{X}^{\\prime} \\mathbf{X}\\right)^{-1}\n",
    "$$\n",
    "\n",
    "**<span style=\"color:red\">HC1:</span>** (most common in *econometrics*)\n",
    "\n",
    "$$\n",
    "\\widehat{\\mathbf{V}}_{\\widehat{\\boldsymbol{\\beta}}}^{\\mathrm{HCl}}=\\left(\\frac{n}{n-k-1}\\right)\\left(\\mathbf{X}^{\\prime} \\mathbf{X}\\right)^{-1}\\left(\\sum_{i=1}^{n} \\mathbf{x}_{i} \\widehat{e}_{i}^{2}\\mathbf{x}_{i}^{\\prime}\\right)\\left(\\mathbf{X}^{\\prime} \\mathbf{X}\\right)^{-1}\n",
    "$$\n",
    "\n",
    "**<span style=\"color:red\">HC2:</span>**\n",
    "\n",
    "$$\n",
    "\\widehat{\\mathbf{V}}_{\\widehat{\\boldsymbol{\\beta}}}^{\\mathrm{HC2}}=\\left(\\mathbf{X}^{\\prime} \\mathbf{X}\\right)^{-1}\\left(\\sum_{i=1}^{n} \\mathbf{x}_{i} \\left(1-h_{i i}\\right)^{-1}\\widehat{e}_{i}^{2} \\mathbf{x}_{i}^{\\prime} \\right)\\left(\\mathbf{X}^{\\prime} \\mathbf{X}\\right)^{-1}\n",
    "$$\n",
    "\n",
    "**<span style=\"color:red\">HC3:</span>**\n",
    "\n",
    "$$\n",
    "\\widehat{\\mathbf{V}}_{\\widehat{\\boldsymbol{\\beta}}}^{\\mathrm{HC3}}=\\left(\\mathbf{X}^{\\prime} \\mathbf{X}\\right)^{-1}\\left(\\sum_{i=1}^{n} \\mathbf{x}_{i} \\left(1-h_{i i}\\right)^{-2}\\widehat{e}_{i}^{2} \\mathbf{x}_{i}^{\\prime} \\right)\\left(\\mathbf{X}^{\\prime} \\mathbf{X}\\right)^{-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "💻 Unfortunately the default variance covariance matrix reported in ```lm``` corresponds to the _homoskedastic_ case, i.e., $\\widehat{\\sigma}^2(\\mathbf{X}^{\\prime}\\mathbf{X})^{-1}$. All four estimators can be computed using the ```sandwich``` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## installing the 'sandwich' package if not previously installed\n",
    "if (!require(sandwich)) install.packages('sandwich')\n",
    "\n",
    "## loading the packages\n",
    "library(sandwich)\n",
    "\n",
    "## OLS: calculating estimated asymptotic vcov matrices\n",
    "#vcovHC(ols,type=\"HC0\")\n",
    "vcovHC(ols,type=\"HC1\")\n",
    "#vcovHC(ols,type=\"HC2\")\n",
    "#vcovHC(ols,type=\"HC3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.153087 -0.0171   -0.010783 -0.000082 -0.006901 -0.001531  0.000706\n",
      "  -0.000783 -0.000196]\n",
      " [-0.0171    0.008526 -0.000417  0.00002   0.000403  0.000481 -0.000067\n",
      "   0.000125 -0.000089]\n",
      " [-0.010783 -0.000417  0.001985  0.000004  0.000096 -0.000021 -0.000065\n",
      "   0.000007 -0.000026]\n",
      " [-0.000082  0.00002   0.000004  0.000004  0.000003  0.000002 -0.000002\n",
      "   0.000001 -0.000001]\n",
      " [-0.006901  0.000403  0.000096  0.000003  0.00066   0.000078 -0.000025\n",
      "   0.000037  0.000057]\n",
      " [-0.001531  0.000481 -0.000021  0.000002  0.000078  0.000053 -0.000006\n",
      "   0.000006  0.000005]\n",
      " [ 0.000706 -0.000067 -0.000065 -0.000002 -0.000025 -0.000006  0.000006\n",
      "  -0.000003 -0.000001]\n",
      " [-0.000783  0.000125  0.000007  0.000001  0.000037  0.000006 -0.000003\n",
      "   0.000017 -0.000001]\n",
      " [-0.000196 -0.000089 -0.000026 -0.000001  0.000057  0.000005 -0.000001\n",
      "  -0.000001  0.000013]]\n"
     ]
    }
   ],
   "source": [
    "## OLS: calculating estimated asymptotic vcov matrices\n",
    "#print(ols.cov_HC0)\n",
    "print(ols.cov_HC1)\n",
    "#print(ols.cov_HC2)\n",
    "#print(ols.cov_HC3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<ins>(Asymptotic) Standard Errors</ins>:\n",
    "\n",
    "These corresponds to the estimator of the standard deviation of the distribution of the OLS estimator $\\widehat{\\boldsymbol{\\beta}}$, i.e., \n",
    "\n",
    "$$\n",
    "s\\left(\\widehat{\\beta}_{j}\\right)=\\sqrt{\\widehat{\\mathbf{V}}^{\\mathrm{HC?}}_{\\widehat{\\beta}_{j}}}=\\sqrt{\\left[\\widehat{\\mathbf{V}}^{\\mathrm{HC?}}_{\\widehat{\\boldsymbol{\\beta}}}\\right]_{j j}},\n",
    "$$\n",
    "\n",
    "for $?=0,1,2,3$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "💻 Computationally they simply correspond to the square root of the main diagonal elements of the $\\widehat{\\mathbf{V}}^{\\mathrm{HC0}}_{\\widehat{\\boldsymbol{\\beta}}}$, $\\widehat{\\mathbf{V}}^{\\mathrm{HC1}}_{\\widehat{\\boldsymbol{\\beta}}}$, $\\widehat{\\mathbf{V}}^{\\mathrm{HC2}}_{\\widehat{\\boldsymbol{\\beta}}}$, or $\\widehat{\\mathbf{V}}^{\\mathrm{HC3}}_{\\widehat{\\boldsymbol{\\beta}}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data.frame(se.HC0=sqrt(diag(vcovHC(ols,type=\"HC0\"))),se.HC1=sqrt(diag(vcovHC(ols,type=\"HC1\"))),\n",
    "           se.HC2=sqrt(diag(vcovHC(ols,type=\"HC2\"))),se.HC3=sqrt(diag(vcovHC(ols,type=\"HC3\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>se_HC0</th>\n",
       "      <th>se_HC1</th>\n",
       "      <th>se_HC2</th>\n",
       "      <th>se_HC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>0.387768</td>\n",
       "      <td>0.391263</td>\n",
       "      <td>0.396025</td>\n",
       "      <td>0.404742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lnox</th>\n",
       "      <td>0.091514</td>\n",
       "      <td>0.092339</td>\n",
       "      <td>0.092993</td>\n",
       "      <td>0.094534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lproptax</th>\n",
       "      <td>0.044156</td>\n",
       "      <td>0.044554</td>\n",
       "      <td>0.045101</td>\n",
       "      <td>0.046080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crime</th>\n",
       "      <td>0.001904</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>0.002116</td>\n",
       "      <td>0.002369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rooms</th>\n",
       "      <td>0.025467</td>\n",
       "      <td>0.025696</td>\n",
       "      <td>0.026115</td>\n",
       "      <td>0.026799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dist</th>\n",
       "      <td>0.007207</td>\n",
       "      <td>0.007272</td>\n",
       "      <td>0.007322</td>\n",
       "      <td>0.007441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radial</th>\n",
       "      <td>0.002521</td>\n",
       "      <td>0.002544</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.002692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stratio</th>\n",
       "      <td>0.004088</td>\n",
       "      <td>0.004125</td>\n",
       "      <td>0.004155</td>\n",
       "      <td>0.004226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lowstat</th>\n",
       "      <td>0.003522</td>\n",
       "      <td>0.003554</td>\n",
       "      <td>0.003609</td>\n",
       "      <td>0.003699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             se_HC0    se_HC1    se_HC2    se_HC3\n",
       "Intercept  0.387768  0.391263  0.396025  0.404742\n",
       "lnox       0.091514  0.092339  0.092993  0.094534\n",
       "lproptax   0.044156  0.044554  0.045101  0.046080\n",
       "crime      0.001904  0.001922  0.002116  0.002369\n",
       "rooms      0.025467  0.025696  0.026115  0.026799\n",
       "dist       0.007207  0.007272  0.007322  0.007441\n",
       "radial     0.002521  0.002544  0.002600  0.002692\n",
       "stratio    0.004088  0.004125  0.004155  0.004226\n",
       "lowstat    0.003522  0.003554  0.003609  0.003699"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'se_HC0':ols.HC0_se,'se_HC1':ols.HC1_se,'se_HC2':ols.HC2_se,'se_HC3':ols.HC3_se})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<ins>$t$-statistic</ins>:\n",
    "\n",
    "$$t=\\frac{\\widehat{\\beta}_j-\\beta_j}{s(\\widehat{\\beta}_j)}\\stackrel{d}{\\longrightarrow}N(0,1).$$\n",
    "\n",
    "<p style='text-align: right;'> <a href=\"https://en.wikipedia.org/wiki/T-statistic\" style=\"color: #cc0000\">t-statistic</a></p>\n",
    "<p style='text-align: right;'> <a href=\"https://en.wikipedia.org/wiki/Normal_distribution#Definition\" style=\"color: #cc0000\">Standard Normal</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "💻 Most statistical packages will use the Student's $t$ distribution with $n-k-1$ degrees-of-freedom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## installing the 'lmtest' package if not previously installed\n",
    "if (!require(lmtest)) install.packages('lmtest')\n",
    "\n",
    "## loading the packages\n",
    "library(lmtest)\n",
    "\n",
    "## OLS: calculating standard t-statistics for 'significance'\n",
    "coeftest(ols, vcov = vcovHC, type = \"HC1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<ins>(Asymptotic) Confidence Interval</ins>:\n",
    "\n",
    "The OLS estimator $\\widehat{\\beta}_j$ is called a _point estimator_ of the unknown slope parameter $\\beta_j$. A broader concept is a _set estimator_ $\\widehat{C}=[\\widehat{L},\\widehat{U}]$ which is an _interval estimator_ of $\\beta_j$. An interval estimator $\\widehat{C}$ is called a **confidence interval** when the goal is to set the coverage probability\n",
    "to equal a pre-specified target such as $90 \\%$ or $95 \\%$. The conventional confidence interval for $\\beta_j$ takes the form\n",
    "\n",
    "$$\n",
    "\\widehat{C}=[\\widehat{\\beta}_j-c\\cdot s(\\widehat{\\beta}_j),\\widehat{\\beta}_j+c\\cdot s(\\widehat{\\beta}_j)],\n",
    "$$\n",
    "\n",
    "where $c$ equals the $1-\\alpha$ [quantile](https://en.wikipedia.org/wiki/Quantile) of the distribution of $|Z|$, i.e., $c$ is equivalent to the $1-\\alpha/2$ quantile of the standard normal distribution.\n",
    "\n",
    "<p style='text-align: right;'> <a href=\"https://en.wikipedia.org/wiki/Confidence_interval\" style=\"color: #cc0000\">Confidence Interval</a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## OLS: calculating asymptotic 90% confidence interval\n",
    "coefci(ols, level = 0.90, vcov = vcovHC, type = \"HC1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Regression Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In the linear regression model the conditional mean of $y_{i}$ given $\\mathbf{x}_{i}=\\mathbf{x}$ is\n",
    "$$\n",
    "m(\\mathbf{x})=E\\left(y_{i} | \\mathbf{x}_{i}=\\mathbf{x}\\right)=\\mathbf{x}^{\\prime} \\beta\n",
    "$$\n",
    "Thus an asymptotic 95% confidence interval for $m(\\mathbf{x})$ is\n",
    "$$\n",
    "\\left[\\mathbf{x}^{\\prime} \\widehat{\\boldsymbol{\\beta}} \\pm 1.96 \\sqrt{\\mathbf{x}^{\\prime} \\widehat{\\mathbf{V}}_{\\widehat{\\boldsymbol{\\beta}}}^{\\mathrm{HC?}} \\mathbf{x}}\\right]\n",
    "$$\n",
    "for $?=0,1,2,3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "## installing the 'mgcv' package if not previously installed\n",
    "if (!require(mgcv)) install.packages('mgcv')\n",
    "\n",
    "## loading the packages\n",
    "library(mgcv)\n",
    "\n",
    "## OLS: performing OLS using the 'gam' function in 'mgcv'\n",
    "ols.gam <- gam(f,data=hprice2)\n",
    "\n",
    "## OLS: replacing the default homoskedastic vcov\n",
    "ols.gam$Vp <- vcovHC(ols,type=\"HC1\")\n",
    "\n",
    "## OLS: creating the x_i=mean(x)\n",
    "attach(hprice2)\n",
    "new.dat=data.frame(lnox=mean(lnox),lproptax=mean(lproptax),\n",
    "                   crime=mean(crime),rooms=mean(rooms),\n",
    "                   dist=mean(dist),radial=mean(radial),\n",
    "                   stratio=mean(stratio),lowstat=mean(lowstat))\n",
    "detach(hprice2)\n",
    "\n",
    "## OLS: using the predict command to get the robust s.e.\n",
    "reg.int <- predict(ols.gam,newdata=new.dat,se.fit=TRUE)\n",
    "\n",
    "## OLS: manually estimating the (robust) regression interval\n",
    "data.frame(L.hat=reg.int$fit-1.96*reg.int$se.fit,U.hat=reg.int$fit+1.96*reg.int$se.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Forecast Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Suppose we are given a value of the regressor vector $\\mathbf{x}_{n+1}$ for an individual outside the sample, and\n",
    "we want to forecast (guess) $y_{n+1}$ for this individual. This is equivalent to forecasting $y_{n+1}$ given $\\mathbf{x}_{n+1}=\\mathbf{x}$, which will generally be a function of $\\mathbf{x}$. A reasonable forecasting rule is the conditional mean $m(\\mathbf{x})$ as it is the mean-square-minimizing forecast. A point forecast is the estimated conditional mean $\\widehat{m}(\\mathbf{x})=\\mathbf{x}^{\\prime} \\widehat{\\beta}$. We would also like a measure of uncertainty for the forecast.\n",
    "\n",
    "The forecast error is $\\widehat{e}_{n+1}=y_{n+1}-\\widehat{m}(\\mathbf{x})=e_{n+1}-\\mathbf{x}^{\\prime}(\\widehat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta})$. As the out-of-sample error $e_{n+1}$ is independent of the in-sample estimate $\\widehat{\\boldsymbol{\\beta}}$, this has conditional variance\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "E\\left(\\widehat{e}_{n+1}^{2} | \\mathbf{x}_{n+1}=\\mathbf{x}\\right) &=E\\left(e_{n+1}^{2}-2 \\mathbf{x}^{\\prime}(\\widehat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta}) e_{n+1}+\\mathbf{x}^{\\prime}(\\hat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta})(\\hat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta})^{\\prime} \\mathbf{x} | \\mathbf{x}_{n+1}=\\mathbf{x}\\right) \\\\ &=E\\left(e_{n+1}^{2} | \\mathbf{x}_{n+1}=\\mathbf{x}\\right)+\\mathbf{x}^{\\prime} E[(\\widehat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta})(\\widehat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta})^{\\prime}|\\mathbf{x}_{n+1}=\\mathbf{x}] \\mathbf{x} \\\\ &=\\sigma^{2}(\\mathbf{x})+\\mathbf{x}^{\\prime} \\mathbf{V}_{\\widehat{\\boldsymbol{\\beta}}} \\mathbf{x} \\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Under homoskedasticity $E\\left(e_{n+1}^{2} | \\mathbf{x}_{n+1}\\right)=\\sigma^{2}$. In this case $\\widehat{\\sigma}^{2}+\\mathbf{x}^{\\prime} \\widehat{\\mathbf{V}}_{\\widehat{\\beta}}^{\\mathrm{HC?}} \\mathbf{x}$ is a consistent estimator of this conditional variance, so a standard error for the forecast is $\\widehat{s}(\\mathbf{x})=\\sqrt{\\widehat{\\sigma}^{2}+\\mathbf{x}^{\\prime} \\widehat{\\mathbf{V}}_{\\widehat{\\boldsymbol{\\beta}}}^{\\mathrm{HC?}} \\mathbf{x}}$, and the conventional 95% forecast insterval for $y_{n+1}$ uses a normal approximation and sets\n",
    "\n",
    "$$\\left[\\mathbf{x}^{\\prime} \\widehat{\\boldsymbol{\\beta}} \\pm 1.96 \\widehat{s}(\\mathbf{x})\\right].$$\n",
    "\n",
    "🛑 This interval is only valid if $e_{n+1}$ comes from a _homoskedastic_ normal distribution, i.e., $e_{n+1}\\sim N(0,\\sigma^2)$!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "💻 We now _manually_ calculate the forecast interval for the same mean values of $\\mathbf{x}$ as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## OLS: manually estimating the forecast interval\n",
    "s.hat <- sqrt(summary(ols)$sigma^2+reg.int$se.fit^2)\n",
    "data.frame(L.hat=reg.int$fit-1.96*s.hat,\n",
    "           U.hat=reg.int$fit+1.96*s.hat)"
   ]
  }
 ],
 "metadata": {
  "author": "lde",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
