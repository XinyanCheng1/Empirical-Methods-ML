{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Resampling Methods\n",
    "\n",
    "There are two most commonly used _resampling methods,_ _cross-validation,_ and the _bootstrap_.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: wooldridge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    lprice    lland    larea nbh rooms      cbd y81    ldist baths age agesq\n",
      "1 11.00210 8.429017 7.414573   4     7 8.006368   0 9.277999     1  48  2304\n",
      "2 10.59663 9.032409 7.867871   4     6 8.294050   0 9.305651     2  83  6889\n",
      "3 10.43412 8.517193 7.042286   4     6 8.294050   0 9.350102     1  58  3364\n",
      "4 11.06507 9.210340 7.035269   4     5 8.294050   0 9.384294     1  11   121\n",
      "5 10.69195 9.210340 7.532624   4     5 8.294050   0 9.400961     1  48  2304\n",
      "6 10.73640 9.159047 7.484369   4     6 8.006368   0 9.210340     3  78  6084\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "## removing everything from memory\n",
    "rm(list=ls())\n",
    "## turning all warnings off\n",
    "options(warn=-1)\n",
    "\n",
    "## installing the 'wooldridge' package if not previously installed\n",
    "if (!require(wooldridge)) install.packages('wooldridge')\n",
    "\n",
    "## loading the packages\n",
    "library(wooldridge)\n",
    "\n",
    "## see the raw data\n",
    "head(hprice3)\n",
    "\n",
    "## pre-processing the data set\n",
    "hprice3_processed <- subset(hprice3,select=c(\"lprice\",\"lland\",\"larea\",\"nbh\",\"rooms\",\"cbd\",\"y81\",\"ldist\",\"baths\",\"age\",\"agesq\"))\n",
    "hprice3_processed$cbd <- log(hprice3_processed$cbd)\n",
    "hprice3_processed$y81 <- as.factor(hprice3_processed$y81)\n",
    "hprice3_processed$nbh <- as.factor(hprice3_processed$nbh)\n",
    "\n",
    "head(hprice3_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      lprice     lland     larea nbh  rooms       cbd y81     ldist  baths  \\\n",
      "0  11.002100  8.429017  7.414573   4      7  8.006368   0  9.277999      1   \n",
      "1  10.596635  9.032409  7.867871   4      6  8.294050   0  9.305651      2   \n",
      "2  10.434115  8.517193  7.042286   4      6  8.294050   0  9.350102      1   \n",
      "3  11.065075  9.210340  7.035269   4      5  8.294050   0  9.384294      1   \n",
      "4  10.691945  9.210340  7.532624   4      5  8.294050   0  9.400961      1   \n",
      "5  10.736397  9.159047  7.484369   4      6  8.006368   0  9.210340      3   \n",
      "\n",
      "   age   agesq  \n",
      "0   48  2304.0  \n",
      "1   83  6889.0  \n",
      "2   58  3364.0  \n",
      "3   11   121.0  \n",
      "4   48  2304.0  \n",
      "5   78  6084.0  \n"
     ]
    }
   ],
   "source": [
    "from numpy import log\n",
    "import wooldridge as woo\n",
    "hprice3 = woo.dataWoo('hprice3')\n",
    "\n",
    "hprice3_processed = hprice3[['lprice','lland','larea','nbh','rooms','cbd','y81','ldist','baths','age','agesq']].copy()\n",
    "# In Python, the equal sign (“=”), creates a reference to that object.\n",
    "# Because of this, you’ll run into issues when trying to modify a copied dataframe.\n",
    "# In order to avoid this, you’ll want to use the .copy() method to create a brand new object, that isn’t just a reference to the original.\n",
    "\n",
    "hprice3_processed['cbd'] = log(hprice3_processed['cbd'])\n",
    "hprice3_processed['y81'] = hprice3_processed['y81'].astype('category')\n",
    "hprice3_processed['nbh'] = hprice3_processed['nbh'].astype('category')\n",
    "print(hprice3_processed.head(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-Validation\n",
    "\n",
    "These methods are used to do two things\n",
    "\n",
    "1. _Model Assessment_ - the process of evaluating a model's performance.\n",
    "2. _Model Selection_ - the process of selecting the proper level of flexibility for a model.\n",
    "\n",
    "Since models are 'trained' using training data sets, they are by construction suitable to fit data in these training data sets only (they were fit by minimizing in-sample fitted errors). Since the validation set was not used to fit the model, these set of observations can be used to assess the performance of the model and therefore will allow us to do model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: caret\n",
      "\n",
      "R[write to console]: Loading required package: lattice\n",
      "\n",
      "R[write to console]: Loading required package: ggplot2\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t321 obs. of  16 variables:\n",
      " $ lprice: num  11 10.6 10.4 11.1 10.7 ...\n",
      " $ lland : num  8.43 9.03 8.52 9.21 9.21 ...\n",
      " $ larea : num  7.41 7.87 7.04 7.04 7.53 ...\n",
      " $ nbh.1 : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ nbh.2 : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ nbh.3 : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ nbh.4 : num  1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ nbh.5 : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ nbh.6 : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ rooms : num  7 6 6 5 5 6 6 6 8 5 ...\n",
      " $ cbd   : num  8.01 8.29 8.29 8.29 8.29 ...\n",
      " $ y81.1 : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ ldist : num  9.28 9.31 9.35 9.38 9.4 ...\n",
      " $ baths : num  1 2 1 1 1 3 2 2 2 2 ...\n",
      " $ age   : num  48 83 58 11 48 78 22 78 42 41 ...\n",
      " $ agesq : num  2304 6889 3364 121 2304 ...\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "## installing the 'caret' package if not previously installed\n",
    "if (!require(caret)) install.packages('caret')\n",
    "\n",
    "## loading the packages\n",
    "library(caret)\n",
    "\n",
    "## continue pre-processing\n",
    "## converting every categorical variable to numerical using dummy variables\n",
    "dmy <- dummyVars(\" ~ .\", data = hprice3_processed,fullRank = T)\n",
    "hprice3_processed <- data.frame(predict(dmy, newdata = hprice3_processed))\n",
    "\n",
    "## looking at the structure of caret package.\n",
    "str(hprice3_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      lprice     lland     larea  rooms       cbd     ldist  baths  age  \\\n",
      "0  11.002100  8.429017  7.414573      7  8.006368  9.277999      1   48   \n",
      "1  10.596635  9.032409  7.867871      6  8.294050  9.305651      2   83   \n",
      "2  10.434115  8.517193  7.042286      6  8.294050  9.350102      1   58   \n",
      "3  11.065075  9.210340  7.035269      5  8.294050  9.384294      1   11   \n",
      "4  10.691945  9.210340  7.532624      5  8.294050  9.400961      1   48   \n",
      "5  10.736397  9.159047  7.484369      6  8.006368  9.210340      3   78   \n",
      "\n",
      "    agesq  nbh_1  nbh_2  nbh_3  nbh_4  nbh_5  nbh_6  y81_1  \n",
      "0  2304.0      0      0      0      1      0      0      0  \n",
      "1  6889.0      0      0      0      1      0      0      0  \n",
      "2  3364.0      0      0      0      1      0      0      0  \n",
      "3   121.0      0      0      0      1      0      0      0  \n",
      "4  2304.0      0      0      0      1      0      0      0  \n",
      "5  6084.0      0      0      0      1      0      0      0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hprice3_processed = pd.get_dummies(hprice3_processed,drop_first=True).copy()\n",
    "# Dropping the First Categorical Variable with 'drop_first=True'\n",
    "\n",
    "print(hprice3_processed.head(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Validation Set Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![validation_set_approach.png](img/validation_set_approach.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A schematic display of the validation set approach. A set of $n$ observations are randomly split into a training set (shown in blue, containing observations 7, 22, and 13, among others) and a validation set (shown in beige, and containing observation 91, among others). The statistical learning method is fit on the training set, and its performance is evaluated on the validation set. This can be done many (say $J$) times randomly and then all model assessment measures like $RMSE$, $\\bar{R}^2$, $C_p$, $BIC$, and $AIC$ can be calculated many (say $J$) times.\n",
    "\n",
    "<ins>*Note*</ins>: Recall that if we have a sample $\\{y_1,y_2,\\ldots,y_m\\}$ for which we have predicted $\\{\\widehat{y}_1,\\widehat{y}_2,\\ldots,\\widehat{y}_m\\}$, then the $MSE$ for these samples is defined as\n",
    "\n",
    "$$\n",
    " \\begin{aligned}\n",
    " MSE = \\frac{1}{m}\\sum_{j=1}^m (y_j-\\widehat{y}_j)^2\\text{,}\n",
    " \\end{aligned}\n",
    "$$ \n",
    " and the $RMSE$ is simply defined as $RMSE=\\sqrt{MSE}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t259 obs. of  16 variables:\n",
      " $ lprice: num  11 10.6 10.4 11.1 10.7 ...\n",
      " $ lland : num  8.43 9.03 8.52 9.21 9.21 ...\n",
      " $ larea : num  7.41 7.87 7.04 7.04 7.53 ...\n",
      " $ nbh.1 : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ nbh.2 : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ nbh.3 : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ nbh.4 : num  1 1 1 1 1 1 1 1 1 0 ...\n",
      " $ nbh.5 : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ nbh.6 : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ rooms : num  7 6 6 5 5 6 6 8 6 5 ...\n",
      " $ cbd   : num  8.01 8.29 8.29 8.29 8.29 ...\n",
      " $ y81.1 : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ ldist : num  9.28 9.31 9.35 9.38 9.4 ...\n",
      " $ baths : num  1 2 1 1 1 3 2 2 1 1 ...\n",
      " $ age   : num  48 83 58 11 48 78 22 42 78 38 ...\n",
      " $ agesq : num  2304 6889 3364 121 2304 ...\n",
      "'data.frame':\t62 obs. of  16 variables:\n",
      " $ lprice: num  10.6 10.9 11.3 11 11 ...\n",
      " $ lland : num  8.26 8.98 9.13 9.15 10.71 ...\n",
      " $ larea : num  7.35 7.27 7.52 7.81 7.1 ...\n",
      " $ nbh.1 : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ nbh.2 : num  0 0 0 0 1 1 1 1 0 0 ...\n",
      " $ nbh.3 : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ nbh.4 : num  1 1 1 1 0 0 0 0 0 0 ...\n",
      " $ nbh.5 : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ nbh.6 : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ rooms : num  6 5 7 5 6 7 7 7 6 5 ...\n",
      " $ cbd   : num  8.01 8.01 7.6 7.6 9.8 ...\n",
      " $ y81.1 : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ ldist : num  9.23 9.31 9.2 9.21 10.09 ...\n",
      " $ baths : num  2 2 2 2 1 3 3 3 2 1 ...\n",
      " $ age   : num  78 41 58 70 15 0 0 0 25 18 ...\n",
      " $ agesq : num  6084 1681 3364 4900 225 ...\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "## set the seed for reproducibility\n",
    "set.seed(100)\n",
    "\n",
    "## spliting processed data set into two parts based on outcome: 80% and 20%\n",
    "index <- createDataPartition(hprice3_processed$lprice, p=0.80, list=FALSE)\n",
    "trainSet <- hprice3_processed[ index,]\n",
    "validationSet <- hprice3_processed[-index,]\n",
    "\n",
    "## checking the structure of trainSet\n",
    "str(trainSet)\n",
    "\n",
    "## checking the structure of validationSet\n",
    "str(validationSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 16)\n",
      "(65, 16)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainSet, validationSet = train_test_split(hprice3_processed, test_size=0.2, random_state=42)\n",
    "print(trainSet.shape)\n",
    "print(validationSet.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**__Example__**: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     RMSE  Rsquared       MAE \n",
      "0.1838288 0.7753737 0.1382274 \n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "## train a linear regression model\n",
    "model <- lm(lprice~., data=trainSet)\n",
    "summary(model)\n",
    "\n",
    "## making predictions\n",
    "predictions <- predict(model, validationSet)\n",
    "\n",
    "##summarize results\n",
    "postResample(pred = predictions, obs = validationSet$lprice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of sklearn.metrics:\n",
      "RMSE: 0.21826267267826385\n",
      "R-Squared: 0.753781464779735\n",
      "MAE: 0.1589227085544336\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "linear_reg = LinearRegression()\n",
    "model = linear_reg.fit(trainSet.drop('lprice',axis=1)\\\n",
    "                       ,trainSet['lprice'])\n",
    "predictions = model.predict(validationSet.drop('lprice',axis=1))\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "mse = metrics.mean_squared_error(validationSet['lprice'], predictions)\n",
    "rmse = np.sqrt(mse) #mse**(0.5)  \n",
    "r2 = metrics.r2_score(validationSet['lprice'], predictions)\n",
    "mae = metrics.mean_absolute_error(validationSet['lprice'], predictions)\n",
    "\n",
    "print(\"Results of sklearn.metrics:\")\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R-Squared:\", r2)\n",
    "print(\"MAE:\",mae)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Leave-One-Out Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![LOOCV.png](img/LOOCV.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A schematic display of **LOOCV**. A set of $n$ data points is repeatedly split into a training set (shown in blue) containing all but one observation, and a validation set that contains only that observation (shown in beige). The test error is then estimated by averaging the $n$ resulting $MSE$’s. The first training set contains all but observation 1, the second training set contains all but observation 2, and so forth.\n",
    "\n",
    "Notice that a total of $n$ training data sets containing exactly $n-1$ observations have been constructed along with $n$ corresponding validation data sets containing exactly $1$ observation each.\n",
    "\n",
    "<ins>*Note*</ins>: Recall that in this case we will be using the training data set $\\{(y_1,\\mathbf{x}_1^\\prime),\\ldots,(y_{i-1},\\mathbf{x}_{i-1}^\\prime),(y_{i+1},\\mathbf{x}_{i+1}^\\prime),\\ldots,(y_n,\\mathbf{x}_n^\\prime)\\}$ to predict $y_i$ for $i=1,\\ldots,n$. Therefore the $MSE$ is defined as before for pairs $\\{(y_1,\\widehat{y}_1),\\ldots,(y_n,\\widehat{y}_n)\\}$, i.e., $MSE_i=(y_i-\\widehat{y}_i)^2$, $MSE=n^{-1}\\sum_{i=1}^{n}MSE_i$, and $RMSE=\\sqrt{MSE}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**__Example__**: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized Linear Model \n",
      "\n",
      "321 samples\n",
      " 15 predictor\n",
      "\n",
      "No pre-processing\n",
      "Resampling: Leave-One-Out Cross-Validation \n",
      "Summary of sample sizes: 320, 320, 320, 320, 320, 320, ... \n",
      "Resampling results:\n",
      "\n",
      "  RMSE       Rsquared   MAE      \n",
      "  0.2104742  0.7687971  0.1481018\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "## define training control\n",
    "train_control <- trainControl(method=\"LOOCV\")\n",
    "\n",
    "## train the model\n",
    "model <- train(lprice~., data=hprice3_processed, trControl=train_control, method=\"glm\")\n",
    "\n",
    "## summarize results\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       RMSE       MAE\n",
      "0  0.210474  0.148102\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from numpy import mean\n",
    "from numpy import absolute\n",
    "from numpy import sqrt\n",
    "\n",
    "#define predictor and response variables\n",
    "X = hprice3_processed.drop('lprice',axis=1)\n",
    "y = hprice3_processed['lprice']\n",
    "#define cross-validation method to use\n",
    "cv = LeaveOneOut()\n",
    "\n",
    "#build multiple linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "#use LOOCV to evaluate model\n",
    "scores = cross_validate(model, X, y, scoring={'neg_mean_absolute_error','neg_mean_squared_error'},\n",
    "                         cv=cv, n_jobs=-1)\n",
    "\n",
    "print(pd.DataFrame({'RMSE':[sqrt(mean(absolute(scores['test_neg_mean_squared_error'])))],\\\n",
    "                    'MAE':[mean(absolute(scores['test_neg_mean_absolute_error']))]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### $k$-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![k_fold_CV.PNG](img/k_fold_CV.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A schematic display of 5-fold CV. A set of $n$ observations is randomly split into five non-overlapping groups. Each of these fifths acts as a validation set (shown in beige), and the remainder as a training set (shown in blue). The test error is estimated by averaging the five resulting $MSE$ estimates.\n",
    "\n",
    "Notice that this approach involves randomly dividing the set of observations into $k$ groups (called __folds__), of approximately equal size. The first fold is treated as a validaton set, and the method is fit on the remaining $k−1$ folds.\n",
    "\n",
    "<ins>*Note*</ins>: For each fold $k$, notice that we can calculate the corresponding $MSE$ using the validation set for that fold. Therefore, we will have $MSE_1,\\ldots,MSE_k$ so $MSE=k^{-1}\\sum_{j=1}^{k}MSE_j$, and $RMSE=\\sqrt{MSE}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**__Example__**: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized Linear Model \n",
      "\n",
      "321 samples\n",
      " 15 predictor\n",
      "\n",
      "No pre-processing\n",
      "Resampling: Cross-Validated (10 fold) \n",
      "Summary of sample sizes: 289, 290, 289, 288, 289, 289, ... \n",
      "Resampling results:\n",
      "\n",
      "  RMSE      Rsquared   MAE     \n",
      "  0.207318  0.7762441  0.148628\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "## define training control\n",
    "train_control <- trainControl(method=\"cv\", number=10)\n",
    "\n",
    "## set the seed for reproducibility\n",
    "set.seed(100)\n",
    "\n",
    "## train the model\n",
    "model <- train(lprice~., data=hprice3_processed, trControl=train_control, method=\"glm\")\n",
    "\n",
    "## summarize results\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      RMSE       MAE\n",
      "0  0.20904  0.147189\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# prepare the cross-validation procedure\n",
    "cv = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "#build multiple linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "#use LOOCV to evaluate model\n",
    "scores = cross_validate(model, X, y, scoring={'neg_mean_absolute_error','neg_mean_squared_error'},\n",
    "                         cv=cv, n_jobs=-1)\n",
    "\n",
    "print(pd.DataFrame({'RMSE':[sqrt(mean(absolute(scores['test_neg_mean_squared_error'])))],\\\n",
    "                    'MAE':[mean(absolute(scores['test_neg_mean_absolute_error']))]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "⚠️ If $k=n$ the method is identical to _leave-one-out cross validation_.\n",
    "\n",
    "⚠️ A disadvantage of $k$-fold cross-validation is that the results can be sensitive to the initial random sorting of the observations. Consequently some practitioners calculate the criterion $M$ times and then average the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized Linear Model \n",
      "\n",
      "321 samples\n",
      " 15 predictor\n",
      "\n",
      "No pre-processing\n",
      "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
      "Summary of sample sizes: 289, 290, 289, 288, 289, 289, ... \n",
      "Resampling results:\n",
      "\n",
      "  RMSE       Rsquared   MAE      \n",
      "  0.2061417  0.7842973  0.1481044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "## define training control (Repeat the CV 5 times)\n",
    "train_control <- trainControl(method=\"repeatedcv\", number=10,repeats=5)\n",
    "\n",
    "## set the seed for reproducibility\n",
    "set.seed(100)\n",
    "\n",
    "## train the model\n",
    "model <- train(lprice~., data=hprice3_processed, trControl=train_control, method=\"glm\")\n",
    "\n",
    "## summarize results\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       RMSE       MAE\n",
      "0  0.211966  0.149237\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "#Setup and configure settings for Repeated k-Fold CV (k-folds=10, repeats=5)\n",
    "rcv = RepeatedKFold(n_splits=10, n_repeats=5, random_state=42)\n",
    "\n",
    "#build multiple linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "#use LOOCV to evaluate model\n",
    "scores = cross_validate(model, X, y, scoring={'neg_mean_absolute_error','neg_mean_squared_error'},\n",
    "                         cv=rcv, n_jobs=-1)\n",
    "\n",
    "print(pd.DataFrame({'RMSE':[sqrt(mean(absolute(scores['test_neg_mean_squared_error'])))],\\\n",
    "                    'MAE':[mean(absolute(scores['test_neg_mean_absolute_error']))]}))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
